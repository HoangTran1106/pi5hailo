Train License Plate Recognition on a Custom Dataset
---------------------------------------------------

Here we describe how to finetune Hailo's optical character reader (OCR) model for license plate recognition with your own custom dataset.

Prerequisites
^^^^^^^^^^^^^


* docker (\ `installation instructions <https://docs.docker.com/engine/install/ubuntu/>`_\ )
* nvidia-docker2 (\ `installation instructions <https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html>`_\ )


**NOTE:**\  In case you are using the Hailo Software Suite docker, make sure to run all of the following instructions outside of that docker.


Environment Preparations
^^^^^^^^^^^^^^^^^^^^^^^^


#. 
   **Build the docker image**

   .. code-block::

      
      cd hailo_model_zoo/hailo_models/license_plate_recognition/
      docker build  --build-arg timezone=`cat /etc/timezone` -t license_plate_recognition:v0 .
      

   * This command will build the docker image with the necessary requirements using the Dockerfile that exists in this directory.

#. 
   **Start your docker:**

   .. code-block::

      
      docker run --name "your_docker_name" -it --gpus all --ipc=host -v /path/to/local/data/dir:/path/to/docker/data/dir license_plate_recognition:v0
      


   * ``docker run`` create a new docker container.
   * ``--name <your_docker_name>`` name for your container.
   * ``-it`` runs the command interactively.
   * ``--gpus all`` allows access to all GPUs.
   * ``--ipc=host`` sets the IPC mode for the container.
   * ``-v /path/to/local/data/dir:/path/to/docker/data/dir`` maps ``/path/to/local/data/dir`` from the host to the container. You can use this command multiple times to mount multiple directories.
   * ``license_plate_recognition:v0`` the name of the docker image.

Finetuning and exporting to ONNX
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


#. 
   | **Train the network on your dataset**
   | Once the docker is started, you can train the OCR on your custom dataset.


   * Create a folder with license plates images for training and testing. The folder should contain images whose file names correspond to the plate number, e.g. ``12345678.png``.


   **NOTE:**\  Please make sure the file names **do not** contain characters which are not numbers or letters.


   * 
     Alternatively, you can use the provided jupyter notebook in ``dataset/lp_autogenerate.ipynb`` as an example of how to auto-generate a synthetic dataset of license plates for training. The auto-generation uses several parameters to control the randomness in the dataset, such as allowed characters, font size, font color, character separation etc. (Please refer to the notebook for more details). In order to auto-generate the synthetic dataset, please provide the following:


     * Clean license plate images with no characters in the  ``dataset/plates/`` folder
     * ``.ttf`` font files in the ``dataset/fonts/`` folder

   **NOTE:**\  We recommend the autogenerated training set to contain at least 4 million images

   * 
     Start training on your dataset:


     * Start from our pre-trained weights in ``pre_trained/lprnet.pth`` (you can also download it from `here <https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/HailoNets/LPR/ocr/lprnet/2022-03-09/lprnet.pth>`_\ )
  
       .. code-block::

          
          python train_LPRNet.py --train_img_dirs path/to/train/images --test_img_dirs path/to/test/images --max_epoch 30 --train_batch_size 64 --test_batch_size 32 --resume_epoch 15 --pretrained_model pre_trained/lprnet.pth --save_folder runs/exp0/ --test_interval 2000
          

     * Or train from scratch

       .. code-block::

         python train_LPRNet.py --train_img_dirs path/to/train/images --test_img_dirs path/to/test/images --max_epoch 15 --save_folder runs/exp0/

#. | **Export to ONNX**
   | Export the model to ONNX using the following command:

   .. code-block::

      
      python export.py --onnx lprnet.onnx --weights /path/to/trained/model.pth
      

----

Compile the Model using Hailo Model Zoo
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

You can generate an HEF file for inference on Hailo-8 from your trained ONNX model. In order to do so you need a working model-zoo environment.
Choose the model YAML from our networks configuration directory, i.e. ``hailo_model_zoo/cfg/networks/lprnet.yaml``\ , and run compilation using the model zoo:

.. code-block::

   
   hailomz compile --ckpt lprnet.onnx --calib-path /path/to/calibration/imgs/dir/ --yaml path/to/lprnet.yaml --start-node-names name1 name2 --end-node-names name1
   

* | ``--ckpt`` - path to  your ONNX file.
* | ``--calib-path`` - path to a directory with your calibration images in JPEG/png format
* | ``--yaml`` - path to your configuration YAML file.
* | ``--start-node-names`` and ``--end-node-names`` - node names for customizing parsing behavior (optional).
* | The model zoo will take care of adding the input normalization to be part of the model.

.. note::
  - Since itâ€™s an Hailo model, calibration set must be manually supplied. 
  
  More details about YAML files are presented `here <../../../docs/YAML.rst>`_.
